nameOverride: ""
fullnameOverride: ""

image:
  repository: "docker.io/dorokrok/honeybeepf"
  tag: "latest"
  pullPolicy: IfNotPresent
imagePullSecrets: [] 
podAnnotations: {}

# NOTE: HoneybeePF uses OTLP to send metrics to OTel Collector.
# Prometheus scrapes the OTel Collector's prometheus exporter (port 8889), 
# NOT the agent directly. The agent does NOT expose a /metrics endpoint.
# ServiceMonitor is NOT used - this chart uses annotation-based scraping.

output:
  otlp:
    endpoint: ""  # honeybeepf-otel-collector-opentelemetry-collector:4317
    collectorReleaseName: "honeybeepf-otel-collector"
    port: 4317
    protocol: "grpc"
serviceAccount:
  create: true
  annotations: {}
  name: ""

# Valid values: trace, debug, info, warn, error
rustLog: "info"

builtinProbes:
  block_io:
    enabled: true
  network_latency:
    enabled: false
  gpu_usage:
    enabled: false
  llm:
    enabled: false
    # Custom providers config (optional). Built-in: OpenAI, Anthropic, Gemini
    # Add your own providers here (e.g. Ollama, vLLM, private models).
    providers: []
    # Example:
    # providers:
    #   - name: "ollama"
    #     hosts: ["localhost", "ollama.internal"]
    #     paths: ["/api/generate", "/api/chat"]
    #     response:
    #       usage_path: "usage"               # JSON path to usage object
    #       prompt_tokens: "prompt_eval_count" # Field name for input tokens
    #       completion_tokens: "eval_count"    # Field name for output tokens
    #       model_path: "model"
    #     request_extractor: "messages"       # How to extract prompt text (messages, contents, prompt)
  interval: 1000

customProbes:
  kprobes: []
  uprobes: []
  tracepoints: []

securityContext:
  privileged: true
  readOnlyRootFilesystem: false
  capabilities:
    drop:
      - ALL
    add:
      - SYS_ADMIN
      - BPF
      - NET_ADMIN
      - SYS_RESOURCE
      - SYS_PTRACE
      - DAC_OVERRIDE
resources:
  limits:
    cpu: "1000m"
    memory: "1Gi"
  requests:
    cpu: "200m"
    memory: "512Mi"

nodeSelector:
  kubernetes.io/os: linux

# Debug mode
debug: false